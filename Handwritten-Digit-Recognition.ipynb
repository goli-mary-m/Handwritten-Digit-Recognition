{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c26956",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we use MNIST dataset that contains some grayscale handwritten digit images with size of 28x28 pixels. (28\\*28 = 784 pixels)\n",
    "\n",
    "So we have a fully connected neural network with an input layer, two hidden layers and one output layer.\n",
    "\n",
    "* Layer0: input-layer → 784 neurons (our input is an image with 784 pixels)\n",
    "* Layer1: hidden-layer-1 → 16 neurons\n",
    "* Layer2: hidden-layer-2 → 16 neurons\n",
    "* Layer3: output-layer → 10 neurons (our output is a number between 0 to 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c388c7",
   "metadata": {},
   "source": [
    "- - - -\n",
    "\n",
    "## 1. Reading Dataset\n",
    "\n",
    "MNIST dataset includes training set (60k images) and test set (10k images). We use the code in [this link](https://github.com/HosseinZaredar/Computational-Intelligence/blob/main/read_MNIST.py) to implement this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45752c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "# A function to plot images\n",
    "def show_image(img):\n",
    "    image = img.reshape((28, 28))\n",
    "    plt.imshow(image, 'gray')\n",
    "\n",
    "\n",
    "# Reading The Train Set\n",
    "train_images_file = open('train-images.idx3-ubyte', 'rb')\n",
    "train_images_file.seek(4)\n",
    "num_of_train_images = int.from_bytes(train_images_file.read(4), 'big')\n",
    "train_images_file.seek(16)\n",
    "\n",
    "train_labels_file = open('train-labels.idx1-ubyte', 'rb')\n",
    "train_labels_file.seek(8)\n",
    "\n",
    "train_set = []\n",
    "for n in range(num_of_train_images):\n",
    "    image = np.zeros((784, 1))\n",
    "    for i in range(784):\n",
    "        image[i, 0] = int.from_bytes(train_images_file.read(1), 'big') / 256\n",
    "    \n",
    "    label_value = int.from_bytes(train_labels_file.read(1), 'big')\n",
    "    label = np.zeros((10, 1))\n",
    "    label[label_value, 0] = 1\n",
    "    \n",
    "    train_set.append((image, label))\n",
    "\n",
    "\n",
    "# Reading The Test Set\n",
    "test_images_file = open('t10k-images.idx3-ubyte', 'rb')\n",
    "test_images_file.seek(4)\n",
    "\n",
    "test_labels_file = open('t10k-labels.idx1-ubyte', 'rb')\n",
    "test_labels_file.seek(8)\n",
    "\n",
    "num_of_test_images = int.from_bytes(test_images_file.read(4), 'big')\n",
    "test_images_file.seek(16)\n",
    "\n",
    "test_set = []\n",
    "for n in range(num_of_test_images):\n",
    "    image = np.zeros((784, 1))\n",
    "    for i in range(784):\n",
    "        image[i] = int.from_bytes(test_images_file.read(1), 'big') / 256\n",
    "    \n",
    "    label_value = int.from_bytes(test_labels_file.read(1), 'big')\n",
    "    label = np.zeros((10, 1))\n",
    "    label[label_value, 0] = 1\n",
    "    \n",
    "    test_set.append((image, label))\n",
    "    \n",
    "    \n",
    "# Plotting an image\n",
    "show_image(train_set[0][0])\n",
    "plt.show()    \n",
    "print(train_set[0][1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bff28c",
   "metadata": {},
   "source": [
    "- - - -\n",
    "\n",
    "## 2. Feed Forward\n",
    "\n",
    "We use the following formula for each layer to find the values of output layer : \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    a^{(L+1)} = Sigmoid(w^{(L+1)}×a^{(L)}+b^{(L+1)})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "<br />\n",
    "\n",
    "|Symbol        |Description                  | Size   |\n",
    "|:-------------|:---------------------------:|:------:|\n",
    "|$a^{(L+1)}$   | next layer values           |k\\*1    |\n",
    "|$a^{(L)}$     | current layer values        |n\\*1    |\n",
    "|$w^{(L+1)}$   | weights between two layers  |k\\*n    |\n",
    "|$b^{(L+1)}$   | next layer biases           |k\\*1    |\n",
    "\n",
    "* k = the number of neurons in next layer\n",
    "* n = the number of neurons in current layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d490c",
   "metadata": {},
   "source": [
    "#### Implementation of activation function:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Sigmoid(x) = \\frac{1}{1+e^{-x}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Sigmoid'(x) = Sigmoid(x)×(1-Sigmoid(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f4758f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa6a4e",
   "metadata": {},
   "source": [
    "#### Initializing W matrices and b vectors & Calculating output values for first 100 images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f265c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize W matrices with normalize random values\n",
    "W_layer1 = np.random.normal(size=(16, 784))\n",
    "W_layer2 = np.random.normal(size=(16, 16))\n",
    "W_layer3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# initialize b vectors with zero values\n",
    "b_layer1 = np.zeros((16, 1))\n",
    "b_layer2 = np.zeros((16, 1))\n",
    "b_layer3 = np.zeros((10, 1))\n",
    "\n",
    "# calculate output values for 100 first images\n",
    "train_set_size = 100\n",
    "cnt_correct = 0\n",
    "for i in range(0, train_set_size):\n",
    "\n",
    "    a_layer0 = train_set[i][0]\n",
    "    label = train_set[i][1]\n",
    "    \n",
    "    # find values of hidden layer 1\n",
    "    Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "    a_layer1 = sigmoid(Z1)\n",
    "           \n",
    "    # find values of hidden layer 2\n",
    "    Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "    a_layer2 = sigmoid(Z2)\n",
    "        \n",
    "    # find values of output layer\n",
    "    Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "    a_layer3 = sigmoid(Z3)\n",
    "        \n",
    "    max_value_a_layer3 = a_layer3.max()\n",
    "    output = np.zeros((10, 1))\n",
    "    for j in range(0, 10):\n",
    "        if(a_layer3[j] == max_value_a_layer3):\n",
    "            output[j] = 1\n",
    "    \n",
    "    if((output == label).all()):\n",
    "        cnt_correct += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722dc51",
   "metadata": {},
   "source": [
    "#### Calculating accuracy: \n",
    "{Accuracy should be around 10% at this point!}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e5fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.13\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "accuracy = cnt_correct / train_set_size\n",
    "print(\"Accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d4b0c",
   "metadata": {},
   "source": [
    "- - - -\n",
    "\n",
    "## 3. Backpropagation\n",
    "\n",
    "We can train our model with minimzing cost function and finding proper weights. The most used algorithm to train neural networks is \"Gradient Descent\".\n",
    "In this algorithm, we calculate the partial derivatives of the cost function with respect to the parameters of each layer (with chain rule).\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Cost = \\sum_{j=0}^{n_L-1}(a_j^{(L)}-y_j)^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    (W, b)_{new} = (W, b)_{previous} - αΔCost\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "<br />\n",
    "\n",
    "In this project we use \"Stochastic Gradient Descent\" algorithm:\n",
    "\n",
    "```\n",
    "Pseudocode: \n",
    "\n",
    "Allocate W matrix and vector b for each layer\n",
    "Initialize W from standard normal distribution, and b=0, for each layer\n",
    "Set learning_rate, number_of_epochs and batch_size\n",
    "for i from 0 to number_of_epochs:\n",
    "    Shuffle the train set\n",
    "    for each batch in train set:\n",
    "        Allocate grad_W matrix and grad_b vector for each layer and initialize to 0\n",
    "        for each image in batch:\n",
    "            Compute the output for this image\n",
    "            grad_W += dcost/dW for each layer\n",
    "            grad_b += dcost/db for each layer\n",
    "        W = W - (learning_rate × (grad_W / batch_size))\n",
    "        b = b - (learning_rate × (grad_b / batch_size))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad388d6b",
   "metadata": {},
   "source": [
    "#### Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d02156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize W matrices with normalize random values\n",
    "W_layer1 = np.random.normal(size=(16, 784))\n",
    "W_layer2 = np.random.normal(size=(16, 16))\n",
    "W_layer3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# initialize b vectors with zero values\n",
    "b_layer1 = np.zeros((16, 1))\n",
    "b_layer2 = np.zeros((16, 1))\n",
    "b_layer3 = np.zeros((10, 1))\n",
    "\n",
    "# set hyperparameters\n",
    "number_of_epochs = 20\n",
    "learning_rate = 1\n",
    "batch_size = 10\n",
    "\n",
    "train_set_size = 100\n",
    "number_of_batches = int(train_set_size / batch_size) \n",
    "\n",
    "# values of x_axis and y_axis in cost-epoch plot\n",
    "epochs = []\n",
    "avg_costs_per_epoch = []\n",
    "\n",
    "for i_epoch in range(0, number_of_epochs):\n",
    "    \n",
    "    all_costs = []\n",
    "    \n",
    "    for i_batch in range(0, number_of_batches):\n",
    "        \n",
    "        batch = train_set[batch_size*i_batch : batch_size*(i_batch+1)]\n",
    "        \n",
    "        grad_W_layer1 = np.zeros((16, 784))\n",
    "        grad_W_layer2 = np.zeros((16, 16))\n",
    "        grad_W_layer3 = np.zeros((10, 16))\n",
    "        \n",
    "        grad_b_layer1 = np.zeros((16, 1))\n",
    "        grad_b_layer2 = np.zeros((16, 1))\n",
    "        grad_b_layer3 = np.zeros((10, 1))\n",
    "        \n",
    "        for i_image in range(0, batch_size):\n",
    "            \n",
    "            image = batch[i_image][0]\n",
    "            label = batch[i_image][1]\n",
    "\n",
    "            # compute the output for current image\n",
    "            \n",
    "            a_layer0 = image\n",
    "            # find values of hidden layer 1\n",
    "            Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "            a_layer1 = sigmoid(Z1)\n",
    "            # find values of hidden layer 2\n",
    "            Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "            a_layer2 = sigmoid(Z2)\n",
    "            # find values of output layer\n",
    "            Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "            a_layer3 = sigmoid(Z3)\n",
    "            \n",
    "            # calculate cost function -> cost = Σ(a_layer3 - y)^2\n",
    "            cost = 0\n",
    "            for i in range(0, 10):\n",
    "                a = a_layer3[i]\n",
    "                y = label[i]\n",
    "                cost += (a - y)**2\n",
    "                \n",
    "            \n",
    "            # update grad_W and grad_b for each layer\n",
    "            \n",
    "            # backpropagation -> from last layer (layer_3) to first layer (layer_0)\n",
    "            # j -> current_layer\n",
    "            # k -> previous_layer\n",
    " \n",
    "            # for layer3\n",
    "            all_partial_derivative_cost_a2 = np.zeros((16, 1))\n",
    "            for j in range(0, 10):              \n",
    "                for k in range(0, 16):\n",
    "                    \n",
    "                    partial_derivative_cost_a3 = 2*(a_layer3[j] - label[j])\n",
    "                    partial_derivative_a3_Z = sigmoid_derivative(Z3[j])\n",
    "                    partial_derivative_Z_W = a_layer2[k]\n",
    "                    partial_derivative_Z_b = 1\n",
    "                    partial_derivative_Z_a2 = W_layer3[j][k]\n",
    "                    \n",
    "                    # chain rule -> update W\n",
    "                    partial_derivative_cost_W = partial_derivative_cost_a3 * partial_derivative_a3_Z * partial_derivative_Z_W                  \n",
    "                    grad_W_layer3[j][k] += partial_derivative_cost_W\n",
    "                    \n",
    "                    # calculate partial derivative of cost with respect to a2 (find partial_derivative_cost_a2)\n",
    "                    all_partial_derivative_cost_a2[k, 0] += partial_derivative_cost_a3 * partial_derivative_a3_Z * partial_derivative_Z_a2\n",
    "                    \n",
    "                # chain rule -> update b\n",
    "                partial_derivative_cost_b = partial_derivative_cost_a3 * partial_derivative_a3_Z * partial_derivative_Z_b\n",
    "                grad_b_layer3[j, 0] += partial_derivative_cost_b\n",
    "                \n",
    "                    \n",
    "            # for layer2\n",
    "            all_partial_derivative_cost_a1 = np.zeros((16, 1))\n",
    "            for j in range(0, 16):  \n",
    "                for k in range(0, 16):\n",
    "                    \n",
    "                    partial_derivative_cost_a2 = all_partial_derivative_cost_a2[j]\n",
    "                    partial_derivative_a2_Z = sigmoid_derivative(Z2[j])\n",
    "                    partial_derivative_Z_W = a_layer1[k]\n",
    "                    partial_derivative_Z_b = 1\n",
    "                    partial_derivative_Z_a1 = W_layer2[j][k]\n",
    "                    \n",
    "                    # chain rule -> update W\n",
    "                    partial_derivative_cost_W = partial_derivative_cost_a2 * partial_derivative_a2_Z * partial_derivative_Z_W\n",
    "                    grad_W_layer2[j, k] += partial_derivative_cost_W\n",
    "                    \n",
    "                    # calculate partial derivative of cost with respect to a1 (find partial_derivative_cost_a1)\n",
    "                    all_partial_derivative_cost_a1[k, 0] += partial_derivative_cost_a2 * partial_derivative_a2_Z * partial_derivative_Z_a1\n",
    "                    \n",
    "                # chain rule -> update b\n",
    "                partial_derivative_cost_b = partial_derivative_cost_a2 * partial_derivative_a2_Z * partial_derivative_Z_b\n",
    "                grad_b_layer2[j, 0] += partial_derivative_cost_b\n",
    "                \n",
    " \n",
    "            # for layer1\n",
    "            for j in range(0, 16):\n",
    "                for k in range(0, 784):\n",
    "                    \n",
    "                    partial_derivative_cost_a1 = all_partial_derivative_cost_a1[j]\n",
    "                    partial_derivative_a_Z = sigmoid_derivative(Z1[j])\n",
    "                    partial_derivative_Z_W = a_layer0[k]\n",
    "                    partial_derivative_Z_b = 1\n",
    "                    \n",
    "                    # chain rule -> update W\n",
    "                    partial_derivative_cost_W = partial_derivative_cost_a1 * partial_derivative_a_Z * partial_derivative_Z_W\n",
    "                    grad_W_layer1[j, k] += partial_derivative_cost_W\n",
    "                    \n",
    "                # chain rule -> update b\n",
    "                partial_derivative_cost_b = partial_derivative_cost_a1 * partial_derivative_a_Z * partial_derivative_Z_b\n",
    "                grad_b_layer1[j, 0] += partial_derivative_cost_b    \n",
    "                \n",
    "    \n",
    "\n",
    "        W_layer1 = W_layer1 - (learning_rate * (grad_W_layer1 / batch_size))\n",
    "        W_layer2 = W_layer2 - (learning_rate * (grad_W_layer2 / batch_size))\n",
    "        W_layer3 = W_layer3 - (learning_rate * (grad_W_layer3 / batch_size))\n",
    "        \n",
    "        b_layer1 = b_layer1 - (learning_rate * (grad_b_layer1 / batch_size))\n",
    "        b_layer2 = b_layer2 - (learning_rate * (grad_b_layer2 / batch_size))\n",
    "        b_layer3 = b_layer3 - (learning_rate * (grad_b_layer3 / batch_size))\n",
    "        \n",
    "        \n",
    "        # calculate cost for images in this batch\n",
    "        for i_image in range(0, batch_size):\n",
    "            \n",
    "            image = batch[i_image][0]\n",
    "            label = batch[i_image][1]\n",
    "        \n",
    "            a_layer0 = image\n",
    "            output_label = label\n",
    "            # find values of hidden layer 1\n",
    "            Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "            a_layer1 = sigmoid(Z1)\n",
    "            # find values of hidden layer 2\n",
    "            Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "            a_layer2 = sigmoid(Z2)\n",
    "            # find values of output layer\n",
    "            Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "            a_layer3 = sigmoid(Z3)\n",
    "\n",
    "            # cost function -> cost = Σ(a_layer3 - y)^2\n",
    "            cost = 0\n",
    "            for i in range(0, 10):\n",
    "                a = a_layer3[i]\n",
    "                y = label[i]\n",
    "                cost += (a - y)**2\n",
    "            all_costs.append(cost) \n",
    "\n",
    "    # find average of costs in this epoch\n",
    "    sum = 0\n",
    "    for i in range(0, train_set_size):\n",
    "        sum += all_costs[i]\n",
    "    avg_cost = sum / train_set_size\n",
    "    avg_costs_per_epoch.append(avg_cost) # y_axis\n",
    "    epochs.append(i_epoch) # x_axis   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca323c",
   "metadata": {},
   "source": [
    "#### Calculating accuracy: \n",
    "{Accuracy should be between 25% and 50% at this point!}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "738434ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.77\n"
     ]
    }
   ],
   "source": [
    "# calculate output values for 100 first images\n",
    "cnt_correct = 0\n",
    "for i in range(0, train_set_size):\n",
    "\n",
    "    a_layer0 = train_set[i][0]\n",
    "    label = train_set[i][1]\n",
    "    \n",
    "    # find values of hidden layer 1\n",
    "    Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "    a_layer1 = sigmoid(Z1)\n",
    "    \n",
    "    # find values of hidden layer 2\n",
    "    Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "    a_layer2 = sigmoid(Z2)\n",
    "        \n",
    "    # find values of output layer\n",
    "    Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "    a_layer3 = sigmoid(Z3)\n",
    "        \n",
    "    max_value_a_layer3 = a_layer3.max()\n",
    "    output = np.zeros((10, 1))\n",
    "    for j in range(0, 10):\n",
    "        if(a_layer3[j] == max_value_a_layer3):\n",
    "            output[j] = 1\n",
    "    \n",
    "    if((output == label).all()):\n",
    "        cnt_correct += 1\n",
    "        \n",
    "# calculate accuracy\n",
    "accuracy = cnt_correct / train_set_size\n",
    "print(\"Accuracy =\", accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f093574b",
   "metadata": {},
   "source": [
    "#### Showing the plot of cost over training epoch (model loss plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f448e9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show cost-epoch plot\n",
    "plt.plot(epochs, avg_costs_per_epoch)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('avg cost')\n",
    "plt.title('model loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
