{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c26956",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we use MNIST dataset that contains some grayscale handwritten digit images with size of 28x28 pixels. (28\\*28 = 784 pixels)\n",
    "\n",
    "So we have a fully connected neural network with an input layer, two hidden layers and one output layer.\n",
    "\n",
    "* Layer0: input-layer → 784 neurons (our input is an image with 784 pixels)\n",
    "* Layer1: hidden-layer-1 → 16 neurons\n",
    "* Layer2: hidden-layer-2 → 16 neurons\n",
    "* Layer3: output-layer → 10 neurons (our output is a number between 0 to 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c388c7",
   "metadata": {},
   "source": [
    "- - - -\n",
    "\n",
    "## 1. Reading Dataset\n",
    "\n",
    "MNIST dataset includes training set (60k images) and test set (10k images). We use the code in [this link](https://github.com/HosseinZaredar/Computational-Intelligence/blob/main/read_MNIST.py) to implement this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45752c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "# A function to plot images\n",
    "def show_image(img):\n",
    "    image = img.reshape((28, 28))\n",
    "    plt.imshow(image, 'gray')\n",
    "\n",
    "\n",
    "# Reading The Train Set\n",
    "train_images_file = open('train-images.idx3-ubyte', 'rb')\n",
    "train_images_file.seek(4)\n",
    "num_of_train_images = int.from_bytes(train_images_file.read(4), 'big')\n",
    "train_images_file.seek(16)\n",
    "\n",
    "train_labels_file = open('train-labels.idx1-ubyte', 'rb')\n",
    "train_labels_file.seek(8)\n",
    "\n",
    "train_set = []\n",
    "for n in range(num_of_train_images):\n",
    "    image = np.zeros((784, 1))\n",
    "    for i in range(784):\n",
    "        image[i, 0] = int.from_bytes(train_images_file.read(1), 'big') / 256\n",
    "    \n",
    "    label_value = int.from_bytes(train_labels_file.read(1), 'big')\n",
    "    label = np.zeros((10, 1))\n",
    "    label[label_value, 0] = 1\n",
    "    \n",
    "    train_set.append((image, label))\n",
    "\n",
    "\n",
    "# Reading The Test Set\n",
    "test_images_file = open('t10k-images.idx3-ubyte', 'rb')\n",
    "test_images_file.seek(4)\n",
    "\n",
    "test_labels_file = open('t10k-labels.idx1-ubyte', 'rb')\n",
    "test_labels_file.seek(8)\n",
    "\n",
    "num_of_test_images = int.from_bytes(test_images_file.read(4), 'big')\n",
    "test_images_file.seek(16)\n",
    "\n",
    "test_set = []\n",
    "for n in range(num_of_test_images):\n",
    "    image = np.zeros((784, 1))\n",
    "    for i in range(784):\n",
    "        image[i] = int.from_bytes(test_images_file.read(1), 'big') / 256\n",
    "    \n",
    "    label_value = int.from_bytes(test_labels_file.read(1), 'big')\n",
    "    label = np.zeros((10, 1))\n",
    "    label[label_value, 0] = 1\n",
    "    \n",
    "    test_set.append((image, label))\n",
    "    \n",
    "    \n",
    "# Plotting an image\n",
    "show_image(train_set[0][0])\n",
    "plt.show()    \n",
    "print(train_set[0][1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bff28c",
   "metadata": {},
   "source": [
    "- - - -\n",
    "\n",
    "## 2. Feed Forward\n",
    "\n",
    "We use the following formula for each layer to find the values of output layer : \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    a^{(L+1)} = Sigmoid(w^{(L+1)}×a^{(L)}+b^{(L+1)})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "<br />\n",
    "\n",
    "|Symbol        |Description                  | Size   |\n",
    "|:-------------|:---------------------------:|:------:|\n",
    "|$a^{(L+1)}$   | next layer values           |k\\*1    |\n",
    "|$a^{(L)}$     | current layer values        |n\\*1    |\n",
    "|$w^{(L+1)}$   | weights between two layers  |k\\*n    |\n",
    "|$b^{(L+1)}$   | next layer biases           |k\\*1    |\n",
    "\n",
    "* k = the number of neurons in next layer\n",
    "* n = the number of neurons in current layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d490c",
   "metadata": {},
   "source": [
    "#### Implementation of activation function:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Sigmoid(x) = \\frac{1}{1+e^{-x}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Sigmoid'(x) = Sigmoid(x)×(1-Sigmoid(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4758f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa6a4e",
   "metadata": {},
   "source": [
    "#### Initializing W matrices and b vectors & Calculating output values for first 100 images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f265c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize W matrices with normalize random values\n",
    "W_layer1 = np.random.normal(size=(16, 784))\n",
    "W_layer2 = np.random.normal(size=(16, 16))\n",
    "W_layer3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# initialize b vectors with zero values\n",
    "b_layer1 = np.zeros((16, 1))\n",
    "b_layer2 = np.zeros((16, 1))\n",
    "b_layer3 = np.zeros((10, 1))\n",
    "\n",
    "# calculate output values for 100 first images\n",
    "train_set_size = 100\n",
    "cnt_correct = 0\n",
    "for i in range(0, train_set_size):\n",
    "\n",
    "    a_layer0 = train_set[i][0]\n",
    "    label = train_set[i][1]\n",
    "    \n",
    "    # find values of hidden layer 1\n",
    "    Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "    a_layer1 = sigmoid(Z1)\n",
    "           \n",
    "    # find values of hidden layer 2\n",
    "    Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "    a_layer2 = sigmoid(Z2)\n",
    "        \n",
    "    # find values of output layer\n",
    "    Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "    a_layer3 = sigmoid(Z3)\n",
    "        \n",
    "    max_value_a_layer3 = a_layer3.max()\n",
    "    output = np.zeros((10, 1))\n",
    "    for j in range(0, 10):\n",
    "        if(a_layer3[j] == max_value_a_layer3):\n",
    "            output[j] = 1\n",
    "    \n",
    "    if((output == label).all()):\n",
    "        cnt_correct += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722dc51",
   "metadata": {},
   "source": [
    "#### Calculating accuracy: \n",
    "{Accuracy should be around 10% at this point!}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e5fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.07\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "accuracy = cnt_correct / train_set_size\n",
    "print(\"Accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f57977",
   "metadata": {},
   "source": [
    "- - - -\n",
    "\n",
    "## 3. Backpropagation\n",
    "\n",
    "We can train our model with minimzing cost function and finding proper weights. The most used algorithm to train neural networks is \"Gradient Descent\".\n",
    "In this algorithm, we calculate the partial derivatives of the cost function with respect to the parameters of each layer (with chain rule).\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Cost = \\sum_{j=0}^{n_L-1}(a_j^{(L)}-y_j)^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    (W, b)_{new} = (W, b)_{previous} - αΔCost\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "<br />\n",
    "\n",
    "In this project we use \"Stochastic Gradient Descent\" algorithm:\n",
    "\n",
    "```\n",
    "Pseudocode: \n",
    "\n",
    "Allocate W matrix and vector b for each layer\n",
    "Initialize W from standard normal distribution, and b=0, for each layer\n",
    "Set learning_rate, number_of_epochs and batch_size\n",
    "for i from 0 to number_of_epochs:\n",
    "    Shuffle the train set\n",
    "    for each batch in train set:\n",
    "        Allocate grad_W matrix and grad_b vector for each layer and initialize to 0\n",
    "        for each image in batch:\n",
    "            Compute the output for this image\n",
    "            grad_W += dcost/dW for each layer\n",
    "            grad_b += dcost/db for each layer\n",
    "        W = W - (learning_rate × (grad_W / batch_size))\n",
    "        b = b - (learning_rate × (grad_b / batch_size))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbbc17b",
   "metadata": {},
   "source": [
    "#### Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b888c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize W matrices with normalize random values\n",
    "W_layer1 = np.random.normal(size=(16, 784))\n",
    "W_layer2 = np.random.normal(size=(16, 16))\n",
    "W_layer3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# initialize b vectors with zero values\n",
    "b_layer1 = np.zeros((16, 1))\n",
    "b_layer2 = np.zeros((16, 1))\n",
    "b_layer3 = np.zeros((10, 1))\n",
    "\n",
    "# set hyperparameters\n",
    "number_of_epochs = 20\n",
    "learning_rate = 1\n",
    "batch_size = 10\n",
    "\n",
    "train_set_size = 100\n",
    "number_of_batches = int(train_set_size / batch_size) \n",
    "\n",
    "# values of x_axis and y_axis in cost-epoch plot\n",
    "epochs = []\n",
    "avg_costs_per_epoch = []\n",
    "\n",
    "for i_epoch in range(0, number_of_epochs):\n",
    "    \n",
    "    all_costs = []\n",
    "    \n",
    "    for i_batch in range(0, number_of_batches):\n",
    "        \n",
    "        batch = train_set[batch_size*i_batch : batch_size*(i_batch+1)]\n",
    "        \n",
    "        grad_W_layer1 = np.zeros((16, 784))\n",
    "        grad_W_layer2 = np.zeros((16, 16))\n",
    "        grad_W_layer3 = np.zeros((10, 16))\n",
    "        \n",
    "        grad_b_layer1 = np.zeros((16, 1))\n",
    "        grad_b_layer2 = np.zeros((16, 1))\n",
    "        grad_b_layer3 = np.zeros((10, 1))\n",
    "        \n",
    "        for i_image in range(0, batch_size):\n",
    "            \n",
    "            image = batch[i_image][0]\n",
    "            label = batch[i_image][1]\n",
    "\n",
    "            # compute the output for current image\n",
    "            \n",
    "            a_layer0 = image\n",
    "            # find values of hidden layer 1\n",
    "            Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "            a_layer1 = sigmoid(Z1)\n",
    "            # find values of hidden layer 2\n",
    "            Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "            a_layer2 = sigmoid(Z2)\n",
    "            # find values of output layer\n",
    "            Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "            a_layer3 = sigmoid(Z3)\n",
    "            \n",
    "            # calculate cost function -> cost = Σ{(a_layer3 - y)^2}\n",
    "            cost = 0\n",
    "            for i in range(0, 10):\n",
    "                a = a_layer3[i]\n",
    "                y = label[i]\n",
    "                cost += (a - y)**2\n",
    "                \n",
    "            \n",
    "            # update grad_W and grad_b for each layer\n",
    "            \n",
    "            # backpropagation -> from last layer (layer_3) to first layer (layer_0)\n",
    "            # j -> current_layer\n",
    "            # k -> previous_layer\n",
    " \n",
    "            # for layer3\n",
    "            all_partial_derivative_cost_a2 = np.zeros((16, 1))\n",
    "            for j in range(0, 10):              \n",
    "                for k in range(0, 16):\n",
    "                    \n",
    "                    partial_derivative_cost_a3 = 2*(a_layer3[j] - label[j])\n",
    "                    partial_derivative_a3_Z = sigmoid_derivative(Z3[j])\n",
    "                    partial_derivative_Z_W = a_layer2[k]\n",
    "                    partial_derivative_Z_b = 1\n",
    "                    partial_derivative_Z_a2 = W_layer3[j][k]\n",
    "                    \n",
    "                    # chain rule -> update W\n",
    "                    partial_derivative_cost_W = partial_derivative_cost_a3 * partial_derivative_a3_Z * partial_derivative_Z_W                  \n",
    "                    grad_W_layer3[j][k] += partial_derivative_cost_W\n",
    "                    \n",
    "                    # calculate partial derivative of cost with respect to a2 (find partial_derivative_cost_a2)\n",
    "                    all_partial_derivative_cost_a2[k, 0] += partial_derivative_cost_a3 * partial_derivative_a3_Z * partial_derivative_Z_a2\n",
    "                    \n",
    "                # chain rule -> update b\n",
    "                partial_derivative_cost_b = partial_derivative_cost_a3 * partial_derivative_a3_Z * partial_derivative_Z_b\n",
    "                grad_b_layer3[j, 0] += partial_derivative_cost_b\n",
    "                \n",
    "                    \n",
    "            # for layer2\n",
    "            all_partial_derivative_cost_a1 = np.zeros((16, 1))\n",
    "            for j in range(0, 16):  \n",
    "                for k in range(0, 16):\n",
    "                    \n",
    "                    partial_derivative_cost_a2 = all_partial_derivative_cost_a2[j]\n",
    "                    partial_derivative_a2_Z = sigmoid_derivative(Z2[j])\n",
    "                    partial_derivative_Z_W = a_layer1[k]\n",
    "                    partial_derivative_Z_b = 1\n",
    "                    partial_derivative_Z_a1 = W_layer2[j][k]\n",
    "                    \n",
    "                    # chain rule -> update W\n",
    "                    partial_derivative_cost_W = partial_derivative_cost_a2 * partial_derivative_a2_Z * partial_derivative_Z_W\n",
    "                    grad_W_layer2[j, k] += partial_derivative_cost_W\n",
    "                    \n",
    "                    # calculate partial derivative of cost with respect to a1 (find partial_derivative_cost_a1)\n",
    "                    all_partial_derivative_cost_a1[k, 0] += partial_derivative_cost_a2 * partial_derivative_a2_Z * partial_derivative_Z_a1\n",
    "                    \n",
    "                # chain rule -> update b\n",
    "                partial_derivative_cost_b = partial_derivative_cost_a2 * partial_derivative_a2_Z * partial_derivative_Z_b\n",
    "                grad_b_layer2[j, 0] += partial_derivative_cost_b\n",
    "                \n",
    " \n",
    "            # for layer1\n",
    "            for j in range(0, 16):\n",
    "                for k in range(0, 784):\n",
    "                    \n",
    "                    partial_derivative_cost_a1 = all_partial_derivative_cost_a1[j]\n",
    "                    partial_derivative_a_Z = sigmoid_derivative(Z1[j])\n",
    "                    partial_derivative_Z_W = a_layer0[k]\n",
    "                    partial_derivative_Z_b = 1\n",
    "                    \n",
    "                    # chain rule -> update W\n",
    "                    partial_derivative_cost_W = partial_derivative_cost_a1 * partial_derivative_a_Z * partial_derivative_Z_W\n",
    "                    grad_W_layer1[j, k] += partial_derivative_cost_W\n",
    "                    \n",
    "                # chain rule -> update b\n",
    "                partial_derivative_cost_b = partial_derivative_cost_a1 * partial_derivative_a_Z * partial_derivative_Z_b\n",
    "                grad_b_layer1[j, 0] += partial_derivative_cost_b    \n",
    "                \n",
    "    \n",
    "\n",
    "        W_layer1 = W_layer1 - (learning_rate * (grad_W_layer1 / batch_size))\n",
    "        W_layer2 = W_layer2 - (learning_rate * (grad_W_layer2 / batch_size))\n",
    "        W_layer3 = W_layer3 - (learning_rate * (grad_W_layer3 / batch_size))\n",
    "        \n",
    "        b_layer1 = b_layer1 - (learning_rate * (grad_b_layer1 / batch_size))\n",
    "        b_layer2 = b_layer2 - (learning_rate * (grad_b_layer2 / batch_size))\n",
    "        b_layer3 = b_layer3 - (learning_rate * (grad_b_layer3 / batch_size))\n",
    "        \n",
    "        \n",
    "        # calculate cost for images in this batch\n",
    "        for i_image in range(0, batch_size):\n",
    "            \n",
    "            image = batch[i_image][0]\n",
    "            label = batch[i_image][1]\n",
    "        \n",
    "            a_layer0 = image\n",
    "            output_label = label\n",
    "            # find values of hidden layer 1\n",
    "            Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "            a_layer1 = sigmoid(Z1)\n",
    "            # find values of hidden layer 2\n",
    "            Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "            a_layer2 = sigmoid(Z2)\n",
    "            # find values of output layer\n",
    "            Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "            a_layer3 = sigmoid(Z3)\n",
    "\n",
    "            # calculate cost -> cost = Σ{(a_layer3 - y)^2}\n",
    "            cost = 0\n",
    "            for i in range(0, 10):\n",
    "                a = a_layer3[i]\n",
    "                y = label[i]\n",
    "                cost += (a - y)**2\n",
    "            all_costs.append(cost) \n",
    "\n",
    "    # find average of costs in this epoch\n",
    "    sum = 0\n",
    "    for i in range(0, train_set_size):\n",
    "        sum += all_costs[i]\n",
    "    avg_cost = sum / train_set_size\n",
    "    avg_costs_per_epoch.append(avg_cost) # y_axis\n",
    "    epochs.append(i_epoch) # x_axis   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa8b84",
   "metadata": {},
   "source": [
    "#### Calculating accuracy: \n",
    "{Accuracy should be between 25% and 50% at this point!}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07510c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.61\n"
     ]
    }
   ],
   "source": [
    "# calculate output values for 100 first images\n",
    "cnt_correct = 0\n",
    "for i in range(0, train_set_size):\n",
    "\n",
    "    a_layer0 = train_set[i][0]\n",
    "    label = train_set[i][1]\n",
    "    \n",
    "    # find values of hidden layer 1\n",
    "    Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "    a_layer1 = sigmoid(Z1)\n",
    "    \n",
    "    # find values of hidden layer 2\n",
    "    Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "    a_layer2 = sigmoid(Z2)\n",
    "        \n",
    "    # find values of output layer\n",
    "    Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "    a_layer3 = sigmoid(Z3)\n",
    "        \n",
    "    max_value_a_layer3 = a_layer3.max()\n",
    "    output = np.zeros((10, 1))\n",
    "    for j in range(0, 10):\n",
    "        if(a_layer3[j] == max_value_a_layer3):\n",
    "            output[j] = 1\n",
    "    \n",
    "    if((output == label).all()):\n",
    "        cnt_correct += 1\n",
    "        \n",
    "# calculate accuracy\n",
    "accuracy = cnt_correct / train_set_size\n",
    "print(\"Accuracy =\", accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9c174",
   "metadata": {},
   "source": [
    "#### Showing the plot of cost over training epoch (model loss plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb09e75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show cost-epoch plot\n",
    "plt.plot(epochs, avg_costs_per_epoch)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('avg cost')\n",
    "plt.title('model loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bdfe29",
   "metadata": {},
   "source": [
    "- - - - \n",
    "\n",
    "## 4. Vectorization\n",
    "\n",
    "By using vectorization, we can increase the speed of calculations and reduce the code execution time significantly.\n",
    "In the second section, we vectorized the feedforward and now we implement the vectorized backpropagation.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Vectorized Cost = (\\vec{a}-\\vec{y})^T(\\vec{a}-\\vec{y})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04d64e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize W matrices with normalize random values\n",
    "W_layer1 = np.random.normal(size=(16, 784))\n",
    "W_layer2 = np.random.normal(size=(16, 16))\n",
    "W_layer3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# initialize b vectors with zero values\n",
    "b_layer1 = np.zeros((16, 1))\n",
    "b_layer2 = np.zeros((16, 1))\n",
    "b_layer3 = np.zeros((10, 1))\n",
    "\n",
    "# set hyperparameters\n",
    "number_of_epochs = 200\n",
    "learning_rate = 1\n",
    "batch_size = 10\n",
    "\n",
    "train_set_size = 100\n",
    "number_of_batches = int(train_set_size / batch_size) \n",
    "\n",
    "# values of x_axis and y_axis in cost-epoch plot\n",
    "epochs = []\n",
    "avg_costs_per_epoch = []\n",
    "\n",
    "for i_epoch in range(0, number_of_epochs):\n",
    "    \n",
    "    all_costs = []\n",
    "    \n",
    "    for i_batch in range(0, number_of_batches):\n",
    "\n",
    "        batch = train_set[batch_size*i_batch : batch_size*(i_batch+1)]\n",
    "        \n",
    "        grad_W_layer1 = np.zeros((16, 784))\n",
    "        grad_W_layer2 = np.zeros((16, 16))\n",
    "        grad_W_layer3 = np.zeros((10, 16))\n",
    "        \n",
    "        grad_b_layer1 = np.zeros((16, 1))\n",
    "        grad_b_layer2 = np.zeros((16, 1))\n",
    "        grad_b_layer3 = np.zeros((10, 1))\n",
    "        \n",
    "        for i_image in range(0, batch_size):\n",
    "            \n",
    "            image = batch[i_image][0]\n",
    "            label = batch[i_image][1]\n",
    "            \n",
    "            # compute the output for current image\n",
    "            \n",
    "            a_layer0 = image\n",
    "            # find values of hidden layer 1\n",
    "            Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "            a_layer1 = sigmoid(Z1)\n",
    "            # find values of hidden layer 2\n",
    "            Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "            a_layer2 = sigmoid(Z2)\n",
    "            # find values of output layer\n",
    "            Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "            a_layer3 = sigmoid(Z3)\n",
    "            \n",
    "            # calculate cost function -> cost = Transpose(a_layer3 - y) @ (a_layer3 - y)\n",
    "            cost = np.transpose(a_layer3 - label) @ (a_layer3 - label)\n",
    "                \n",
    "                \n",
    "            # update grad_W and grad_b for each layer\n",
    "            \n",
    "            # backpropagation -> from last layer (layer_3) to first layer (layer_0)\n",
    "            # j -> current_layer\n",
    "            # k -> previous_layer\n",
    " \n",
    "            # for layer3\n",
    "\n",
    "            # chain rule -> update W\n",
    "            partial_derivative_cost_W = (2 * (a_layer3 - label) * sigmoid_derivative(Z3)) @ np.transpose(a_layer2)\n",
    "            grad_W_layer3 += partial_derivative_cost_W\n",
    "            \n",
    "            # chain rule -> update b\n",
    "            partial_derivative_cost_b = 2 * (a_layer3 - label) * sigmoid_derivative(Z3)\n",
    "            grad_b_layer3 += partial_derivative_cost_b\n",
    "                \n",
    "            # calculate partial derivative of cost with respect to a2 (find partial_derivative_cost_a2)\n",
    "            partial_derivative_cost_a2 = np.transpose(W_layer3) @ (2 * (a_layer3 - label) * sigmoid_derivative(Z3))\n",
    "            \n",
    "                \n",
    "            # for layer2\n",
    "\n",
    "            # chain rule -> update W\n",
    "            partial_derivative_cost_W = (partial_derivative_cost_a2 * sigmoid_derivative(Z2)) @ np.transpose(a_layer1)\n",
    "            grad_W_layer2 += partial_derivative_cost_W\n",
    "            \n",
    "            # chain rule -> update b\n",
    "            partial_derivative_cost_b = partial_derivative_cost_a2 * sigmoid_derivative(Z2)\n",
    "            grad_b_layer2 += partial_derivative_cost_b\n",
    "                \n",
    "            # calculate partial derivative of cost with respect to a1 (find partial_derivative_cost_a1)\n",
    "            partial_derivative_cost_a1 = np.transpose(W_layer2) @ (partial_derivative_cost_a2 * sigmoid_derivative(Z2))    \n",
    "                \n",
    "                \n",
    "            # for layer1\n",
    "\n",
    "            # chain rule -> update W\n",
    "            partial_derivative_cost_W = (partial_derivative_cost_a1 * sigmoid_derivative(Z1)) @ np.transpose(a_layer0)\n",
    "            grad_W_layer1 += partial_derivative_cost_W\n",
    "            \n",
    "            # chain rule -> update b\n",
    "            partial_derivative_cost_b = partial_derivative_cost_a1 * sigmoid_derivative(Z1)\n",
    "            grad_b_layer1 += partial_derivative_cost_b\n",
    "                   \n",
    "                \n",
    "        W_layer1 = W_layer1 - (learning_rate * (grad_W_layer1 / batch_size))\n",
    "        W_layer2 = W_layer2 - (learning_rate * (grad_W_layer2 / batch_size))\n",
    "        W_layer3 = W_layer3 - (learning_rate * (grad_W_layer3 / batch_size))\n",
    "        \n",
    "        b_layer1 = b_layer1 - (learning_rate * (grad_b_layer1 / batch_size))\n",
    "        b_layer2 = b_layer2 - (learning_rate * (grad_b_layer2 / batch_size))\n",
    "        b_layer3 = b_layer3 - (learning_rate * (grad_b_layer3 / batch_size))\n",
    "        \n",
    "        \n",
    "        # calculate cost for images in this batch\n",
    "        for i_image in range(0, batch_size):\n",
    "            \n",
    "            image = batch[i_image][0]\n",
    "            label = batch[i_image][1]\n",
    "        \n",
    "            a_layer0 = image\n",
    "            output_label = label\n",
    "            # find values of hidden layer 1\n",
    "            Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "            a_layer1 = sigmoid(Z1)\n",
    "            # find values of hidden layer 2\n",
    "            Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "            a_layer2 = sigmoid(Z2)\n",
    "            # find values of output layer\n",
    "            Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "            a_layer3 = sigmoid(Z3)\n",
    "\n",
    "            # calculate cost -> cost = Transpose(a_layer3 - y) @ (a_layer3 - y)\n",
    "            cost = np.transpose(a_layer3 - label) @ (a_layer3 - label)\n",
    "            all_costs.append(cost[0]) \n",
    "\n",
    "    # find average of costs in this epoch\n",
    "    sum = 0\n",
    "    for i in range(0, train_set_size):\n",
    "        sum += all_costs[i]\n",
    "    avg_cost = sum / train_set_size\n",
    "    avg_costs_per_epoch.append(avg_cost) # y_axis\n",
    "    epochs.append(i_epoch) # x_axis   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04239062",
   "metadata": {},
   "source": [
    "#### Calculating accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee6adbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.98\n"
     ]
    }
   ],
   "source": [
    "# calculate output values for 100 first images\n",
    "cnt_correct = 0\n",
    "for i in range(0, train_set_size):\n",
    "\n",
    "    a_layer0 = train_set[i][0]\n",
    "    label = train_set[i][1]\n",
    "    \n",
    "    # find values of hidden layer 1\n",
    "    Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "    a_layer1 = sigmoid(Z1)\n",
    "    \n",
    "    # find values of hidden layer 2\n",
    "    Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "    a_layer2 = sigmoid(Z2)\n",
    "        \n",
    "    # find values of output layer\n",
    "    Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "    a_layer3 = sigmoid(Z3)\n",
    "        \n",
    "    max_value_a_layer3 = a_layer3.max()\n",
    "    output = np.zeros((10, 1))\n",
    "    for j in range(0, 10):\n",
    "        if(a_layer3[j] == max_value_a_layer3):\n",
    "            output[j] = 1\n",
    "    \n",
    "    if((output == label).all()):\n",
    "        cnt_correct += 1\n",
    "        \n",
    "# calculate accuracy\n",
    "accuracy = cnt_correct / train_set_size\n",
    "print(\"Accuracy =\", accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba0dee",
   "metadata": {},
   "source": [
    "#### Showing the plot of cost over training epoch (model loss plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6924705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show cost-epoch plot\n",
    "plt.plot(epochs, avg_costs_per_epoch)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('avg cost')\n",
    "plt.title('model loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704b1b3",
   "metadata": {},
   "source": [
    "- - - - \n",
    "\n",
    "## 5. Testing \n",
    "\n",
    "In this section instead of using the first 100 images, we use the entire train_set data (60k images) to train our neural network. After that, we test the model with test_set data (10k images).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d315c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize W matrices with normalize random values\n",
    "W_layer1 = np.random.normal(size=(16, 784))\n",
    "W_layer2 = np.random.normal(size=(16, 16))\n",
    "W_layer3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# initialize b vectors with zero values\n",
    "b_layer1 = np.zeros((16, 1))\n",
    "b_layer2 = np.zeros((16, 1))\n",
    "b_layer3 = np.zeros((10, 1))\n",
    "\n",
    "# set hyperparameters\n",
    "number_of_epochs = 5\n",
    "learning_rate = 1\n",
    "batch_size = 50\n",
    "\n",
    "# change train_set_size -> train all data in train_set\n",
    "train_set_size = len(train_set)\n",
    "number_of_batches = int(train_set_size / batch_size) \n",
    "\n",
    "# values of x_axis and y_axis in cost-epoch plot\n",
    "epochs = []\n",
    "avg_costs_per_epoch = []\n",
    "\n",
    "for i_epoch in range(0, number_of_epochs):\n",
    "    \n",
    "    all_costs = []\n",
    "    \n",
    "    for i_batch in range(0, number_of_batches):\n",
    "\n",
    "        batch = train_set[batch_size*i_batch : batch_size*(i_batch+1)]\n",
    "        \n",
    "        grad_W_layer1 = np.zeros((16, 784))\n",
    "        grad_W_layer2 = np.zeros((16, 16))\n",
    "        grad_W_layer3 = np.zeros((10, 16))\n",
    "        \n",
    "        grad_b_layer1 = np.zeros((16, 1))\n",
    "        grad_b_layer2 = np.zeros((16, 1))\n",
    "        grad_b_layer3 = np.zeros((10, 1))\n",
    "        \n",
    "        for i_image in range(0, batch_size):\n",
    "            \n",
    "            image = batch[i_image][0]\n",
    "            label = batch[i_image][1]\n",
    "            \n",
    "            # compute the output for current image\n",
    "            \n",
    "            a_layer0 = image\n",
    "            # find values of hidden layer 1\n",
    "            Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "            a_layer1 = sigmoid(Z1)\n",
    "            # find values of hidden layer 2\n",
    "            Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "            a_layer2 = sigmoid(Z2)\n",
    "            # find values of output layer\n",
    "            Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "            a_layer3 = sigmoid(Z3)\n",
    "            \n",
    "            # calculate cost function -> cost = Transpose(a_layer3 - y) @ (a_layer3 - y)\n",
    "            cost = np.transpose(a_layer3 - label) @ (a_layer3 - label)\n",
    "                \n",
    "                \n",
    "            # update grad_W and grad_b for each layer\n",
    "            \n",
    "            # backpropagation -> from last layer (layer_3) to first layer (layer_0)\n",
    "            # j -> current_layer\n",
    "            # k -> previous_layer\n",
    " \n",
    "            # for layer3\n",
    "\n",
    "            # chain rule -> update W\n",
    "            partial_derivative_cost_W = (2 * (a_layer3 - label) * sigmoid_derivative(Z3)) @ np.transpose(a_layer2)\n",
    "            grad_W_layer3 += partial_derivative_cost_W\n",
    "            \n",
    "            # chain rule -> update b\n",
    "            partial_derivative_cost_b = 2 * (a_layer3 - label) * sigmoid_derivative(Z3)\n",
    "            grad_b_layer3 += partial_derivative_cost_b\n",
    "                \n",
    "            # calculate partial derivative of cost with respect to a2 (find partial_derivative_cost_a2)\n",
    "            partial_derivative_cost_a2 = np.transpose(W_layer3) @ (2 * (a_layer3 - label) * sigmoid_derivative(Z3))\n",
    "            \n",
    "                \n",
    "            # for layer2\n",
    "\n",
    "            # chain rule -> update W\n",
    "            partial_derivative_cost_W = (partial_derivative_cost_a2 * sigmoid_derivative(Z2)) @ np.transpose(a_layer1)\n",
    "            grad_W_layer2 += partial_derivative_cost_W\n",
    "            \n",
    "            # chain rule -> update b\n",
    "            partial_derivative_cost_b = partial_derivative_cost_a2 * sigmoid_derivative(Z2)\n",
    "            grad_b_layer2 += partial_derivative_cost_b\n",
    "                \n",
    "            # calculate partial derivative of cost with respect to a1 (find partial_derivative_cost_a1)\n",
    "            partial_derivative_cost_a1 = np.transpose(W_layer2) @ (partial_derivative_cost_a2 * sigmoid_derivative(Z2))    \n",
    "                \n",
    "                \n",
    "            # for layer1\n",
    "\n",
    "            # chain rule -> update W\n",
    "            partial_derivative_cost_W = (partial_derivative_cost_a1 * sigmoid_derivative(Z1)) @ np.transpose(a_layer0)\n",
    "            grad_W_layer1 += partial_derivative_cost_W\n",
    "            \n",
    "            # chain rule -> update b\n",
    "            partial_derivative_cost_b = partial_derivative_cost_a1 * sigmoid_derivative(Z1)\n",
    "            grad_b_layer1 += partial_derivative_cost_b\n",
    "                   \n",
    "                \n",
    "        W_layer1 = W_layer1 - (learning_rate * (grad_W_layer1 / batch_size))\n",
    "        W_layer2 = W_layer2 - (learning_rate * (grad_W_layer2 / batch_size))\n",
    "        W_layer3 = W_layer3 - (learning_rate * (grad_W_layer3 / batch_size))\n",
    "        \n",
    "        b_layer1 = b_layer1 - (learning_rate * (grad_b_layer1 / batch_size))\n",
    "        b_layer2 = b_layer2 - (learning_rate * (grad_b_layer2 / batch_size))\n",
    "        b_layer3 = b_layer3 - (learning_rate * (grad_b_layer3 / batch_size))\n",
    "        \n",
    "        \n",
    "        # calculate cost for images in this batch\n",
    "        for i_image in range(0, batch_size):\n",
    "            \n",
    "            image = batch[i_image][0]\n",
    "            label = batch[i_image][1]\n",
    "        \n",
    "            a_layer0 = image\n",
    "            output_label = label\n",
    "            # find values of hidden layer 1\n",
    "            Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "            a_layer1 = sigmoid(Z1)\n",
    "            # find values of hidden layer 2\n",
    "            Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "            a_layer2 = sigmoid(Z2)\n",
    "            # find values of output layer\n",
    "            Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "            a_layer3 = sigmoid(Z3)\n",
    "\n",
    "            # calculate cost -> cost = Transpose(a_layer3 - y) @ (a_layer3 - y)\n",
    "            cost = np.transpose(a_layer3 - label) @ (a_layer3 - label)\n",
    "            all_costs.append(cost[0]) \n",
    "\n",
    "    # find average of costs in this epoch\n",
    "    sum = 0\n",
    "    for i in range(0, train_set_size):\n",
    "        sum += all_costs[i]\n",
    "    avg_cost = sum / train_set_size\n",
    "    avg_costs_per_epoch.append(avg_cost) # y_axis\n",
    "    epochs.append(i_epoch) # x_axis   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50376469",
   "metadata": {},
   "source": [
    "#### Showing the plot of cost over training epoch (model loss plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc67ff99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# showing cost-epoch plot\n",
    "\n",
    "plt.plot(epochs, avg_costs_per_epoch)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('avg cost')\n",
    "plt.title('model loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87f203",
   "metadata": {},
   "source": [
    "### Calculating accuracy of model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7374d9c",
   "metadata": {},
   "source": [
    "#### I. For training data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a28d93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train set) = 0.8967833333333334\n"
     ]
    }
   ],
   "source": [
    "train_set_size = len(train_set)\n",
    "\n",
    "cnt_correct = 0\n",
    "for i in range(0, train_set_size):\n",
    "\n",
    "    a_layer0 = train_set[i][0]\n",
    "    label = train_set[i][1]\n",
    "    \n",
    "    Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "    a_layer1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "    a_layer2 = sigmoid(Z2)    \n",
    "    Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "    a_layer3 = sigmoid(Z3)\n",
    "        \n",
    "    max_value_a_layer3 = a_layer3.max()\n",
    "    output = np.zeros((10, 1))\n",
    "    for j in range(0, 10):\n",
    "        if(a_layer3[j] == max_value_a_layer3):\n",
    "            output[j] = 1\n",
    "    \n",
    "    if((output == label).all()):\n",
    "        cnt_correct += 1\n",
    "        \n",
    "accuracy = cnt_correct / train_set_size\n",
    "print(\"Accuracy (train set) =\", accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94610811",
   "metadata": {},
   "source": [
    "#### II. For testing data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "767777c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test set) = 0.8947\n"
     ]
    }
   ],
   "source": [
    "test_set_size = len(test_set)\n",
    "\n",
    "cnt_correct = 0\n",
    "for i in range(0, test_set_size):\n",
    "\n",
    "    a_layer0 = test_set[i][0]\n",
    "    label = test_set[i][1]\n",
    "    \n",
    "    Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "    a_layer1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "    a_layer2 = sigmoid(Z2)    \n",
    "    Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "    a_layer3 = sigmoid(Z3)\n",
    "        \n",
    "    max_value_a_layer3 = a_layer3.max()\n",
    "    output = np.zeros((10, 1))\n",
    "    for j in range(0, 10):\n",
    "        if(a_layer3[j] == max_value_a_layer3):\n",
    "            output[j] = 1\n",
    "    \n",
    "    if((output == label).all()):\n",
    "        cnt_correct += 1\n",
    "        \n",
    "accuracy = cnt_correct / test_set_size\n",
    "print(\"Accuracy (test set) =\", accuracy) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
