{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c26956",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we use MNIST dataset that contains some grayscale handwritten digit images with size of 28x28 pixels. (28\\*28 = 784 pixels)\n",
    "\n",
    "So we have a fully connected neural network with an input layer, two hidden layers and one output layer.\n",
    "\n",
    "* Layer0: input-layer → 784 neurons (our input is an image with 784 pixels)\n",
    "* Layer1: hidden-layer-1 → 16 neurons\n",
    "* Layer2: hidden-layer-2 → 16 neurons\n",
    "* Layer3: output-layer → 10 neurons (our output is a number between 0 to 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c388c7",
   "metadata": {},
   "source": [
    "- - - -\n",
    "\n",
    "## 1. Reading Dataset\n",
    "\n",
    "MNIST dataset includes training set (60k images) and test set (10k images). We use the code in [this link](https://github.com/HosseinZaredar/Computational-Intelligence/blob/main/read_MNIST.py) to implement this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45752c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "# A function to plot images\n",
    "def show_image(img):\n",
    "    image = img.reshape((28, 28))\n",
    "    plt.imshow(image, 'gray')\n",
    "\n",
    "\n",
    "# Reading The Train Set\n",
    "train_images_file = open('train-images.idx3-ubyte', 'rb')\n",
    "train_images_file.seek(4)\n",
    "num_of_train_images = int.from_bytes(train_images_file.read(4), 'big')\n",
    "train_images_file.seek(16)\n",
    "\n",
    "train_labels_file = open('train-labels.idx1-ubyte', 'rb')\n",
    "train_labels_file.seek(8)\n",
    "\n",
    "train_set = []\n",
    "for n in range(num_of_train_images):\n",
    "    image = np.zeros((784, 1))\n",
    "    for i in range(784):\n",
    "        image[i, 0] = int.from_bytes(train_images_file.read(1), 'big') / 256\n",
    "    \n",
    "    label_value = int.from_bytes(train_labels_file.read(1), 'big')\n",
    "    label = np.zeros((10, 1))\n",
    "    label[label_value, 0] = 1\n",
    "    \n",
    "    train_set.append((image, label))\n",
    "\n",
    "\n",
    "# Reading The Test Set\n",
    "test_images_file = open('t10k-images.idx3-ubyte', 'rb')\n",
    "test_images_file.seek(4)\n",
    "\n",
    "test_labels_file = open('t10k-labels.idx1-ubyte', 'rb')\n",
    "test_labels_file.seek(8)\n",
    "\n",
    "num_of_test_images = int.from_bytes(test_images_file.read(4), 'big')\n",
    "test_images_file.seek(16)\n",
    "\n",
    "test_set = []\n",
    "for n in range(num_of_test_images):\n",
    "    image = np.zeros((784, 1))\n",
    "    for i in range(784):\n",
    "        image[i] = int.from_bytes(test_images_file.read(1), 'big') / 256\n",
    "    \n",
    "    label_value = int.from_bytes(test_labels_file.read(1), 'big')\n",
    "    label = np.zeros((10, 1))\n",
    "    label[label_value, 0] = 1\n",
    "    \n",
    "    test_set.append((image, label))\n",
    "    \n",
    "    \n",
    "# Plotting an image\n",
    "show_image(train_set[0][0])\n",
    "plt.show()    \n",
    "print(train_set[0][1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bff28c",
   "metadata": {},
   "source": [
    "- - - -\n",
    "\n",
    "## 2. Feed Forward\n",
    "<a id=\"feed-forward\"></a>\n",
    "\n",
    "We use the following formula for each layer to find the values of output layer : \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    a^{(L+1)} = Sigmoid(w^{(L+1)}×a^{(L)}+b^{(L+1)})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "<br />\n",
    "\n",
    "|Symbol        |Description                  | Size   |\n",
    "|:-------------|:---------------------------:|:------:|\n",
    "|$a^{(L+1)}$   | next layer values           |k\\*1    |\n",
    "|$a^{(L)}$     | current layer values        |n\\*1    |\n",
    "|$w^{(L+1)}$   | weights between two layers  |k\\*n    |\n",
    "|$b^{(L+1)}$   | next layer biases           |k\\*1    |\n",
    "\n",
    "* k = the number of neurons in next layer\n",
    "* n = the number of neurons in current layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d490c",
   "metadata": {},
   "source": [
    "#### Implementation of activation function:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Sigmoid(x) = \\frac{1}{1+e^{-x}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Sigmoid'(x) = Sigmoid(x)×(1-Sigmoid(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f4758f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa6a4e",
   "metadata": {},
   "source": [
    "#### Initializing W matrices and b vectors & Calculating output values for first 100 images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f265c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize W matrices with normalize random values\n",
    "W_layer1 = np.random.normal(size=(16, 784))\n",
    "W_layer2 = np.random.normal(size=(16, 16))\n",
    "W_layer3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# initialize b vectors with zero values\n",
    "b_layer1 = np.zeros((16, 1))\n",
    "b_layer2 = np.zeros((16, 1))\n",
    "b_layer3 = np.zeros((10, 1))\n",
    "\n",
    "# calculate output values for 100 first images\n",
    "train_set_size = 100\n",
    "cnt_correct = 0\n",
    "for i in range(0, train_set_size):\n",
    "\n",
    "    a_layer0 = train_set[i][0]\n",
    "    label = train_set[i][1]\n",
    "    \n",
    "    # find values of hidden layer 1\n",
    "    Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "    a_layer1 = sigmoid(Z1)\n",
    "           \n",
    "    # find values of hidden layer 2\n",
    "    Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "    a_layer2 = sigmoid(Z2)\n",
    "        \n",
    "    # find values of output layer\n",
    "    Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "    a_layer3 = sigmoid(Z3)\n",
    "        \n",
    "    max_value_a_layer3 = a_layer3.max()\n",
    "    output = np.zeros((10, 1))\n",
    "    for j in range(0, 10):\n",
    "        if(a_layer3[j] == max_value_a_layer3):\n",
    "            output[j] = 1\n",
    "    \n",
    "    if((output == label).all()):\n",
    "        cnt_correct += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722dc51",
   "metadata": {},
   "source": [
    "#### Calculating accuracy: \n",
    "{Accuracy should be around 10% at this point!}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e5fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.11\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "accuracy = cnt_correct / train_set_size\n",
    "print(\"Accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f57977",
   "metadata": {},
   "source": [
    "- - - -\n",
    "\n",
    "## 3. Backpropagation\n",
    "\n",
    "We can train our model with minimzing cost function and finding proper weights. The most used algorithm to train neural networks is \"Gradient Descent\".\n",
    "In this algorithm, we calculate the partial derivatives of the cost function with respect to the parameters of each layer (with chain rule).\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Cost = \\sum_{j=0}^{n_L-1}(a_j^{(L)}-y_j)^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    (W, b)_{new} = (W, b)_{previous} - αΔCost\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "<br />\n",
    "\n",
    "In this project we use \"Stochastic Gradient Descent\" algorithm:\n",
    "\n",
    "```\n",
    "Pseudocode: \n",
    "\n",
    "Allocate W matrix and vector b for each layer\n",
    "Initialize W from standard normal distribution, and b=0, for each layer\n",
    "Set learning_rate, number_of_epochs and batch_size\n",
    "for i from 0 to number_of_epochs:\n",
    "    Shuffle the train set\n",
    "    for each batch in train set:\n",
    "        Allocate grad_W matrix and grad_b vector for each layer and initialize to 0\n",
    "        for each image in batch:\n",
    "            Compute the output for this image\n",
    "            grad_W += dcost/dW for each layer\n",
    "            grad_b += dcost/db for each layer\n",
    "        W = W - (learning_rate × (grad_W / batch_size))\n",
    "        b = b - (learning_rate × (grad_b / batch_size))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbbc17b",
   "metadata": {},
   "source": [
    "#### Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b888c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize W matrices with normalize random values\n",
    "W_layer1 = np.random.normal(size=(16, 784))\n",
    "W_layer2 = np.random.normal(size=(16, 16))\n",
    "W_layer3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# initialize b vectors with zero values\n",
    "b_layer1 = np.zeros((16, 1))\n",
    "b_layer2 = np.zeros((16, 1))\n",
    "b_layer3 = np.zeros((10, 1))\n",
    "\n",
    "# set hyperparameters\n",
    "number_of_epochs = 20\n",
    "learning_rate = 1\n",
    "batch_size = 10\n",
    "\n",
    "train_set_size = 100\n",
    "number_of_batches = int(train_set_size / batch_size) \n",
    "\n",
    "# values of x_axis and y_axis in cost-epoch plot\n",
    "epochs = []\n",
    "avg_costs_per_epoch = []\n",
    "\n",
    "for i_epoch in range(0, number_of_epochs):\n",
    "    \n",
    "    all_costs = []\n",
    "    \n",
    "    for i_batch in range(0, number_of_batches):\n",
    "        \n",
    "        batch = train_set[batch_size*i_batch : batch_size*(i_batch+1)]\n",
    "        \n",
    "        grad_W_layer1 = np.zeros((16, 784))\n",
    "        grad_W_layer2 = np.zeros((16, 16))\n",
    "        grad_W_layer3 = np.zeros((10, 16))\n",
    "        \n",
    "        grad_b_layer1 = np.zeros((16, 1))\n",
    "        grad_b_layer2 = np.zeros((16, 1))\n",
    "        grad_b_layer3 = np.zeros((10, 1))\n",
    "        \n",
    "        for i_image in range(0, batch_size):\n",
    "            \n",
    "            image = batch[i_image][0]\n",
    "            label = batch[i_image][1]\n",
    "\n",
    "            # compute the output for current image\n",
    "            \n",
    "            a_layer0 = image\n",
    "            # find values of hidden layer 1\n",
    "            Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "            a_layer1 = sigmoid(Z1)\n",
    "            # find values of hidden layer 2\n",
    "            Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "            a_layer2 = sigmoid(Z2)\n",
    "            # find values of output layer\n",
    "            Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "            a_layer3 = sigmoid(Z3)\n",
    "            \n",
    "            # calculate cost function -> cost = Σ{(a_layer3 - y)^2}\n",
    "            cost = 0\n",
    "            for i in range(0, 10):\n",
    "                a = a_layer3[i]\n",
    "                y = label[i]\n",
    "                cost += (a - y)**2\n",
    "                \n",
    "            \n",
    "            # update grad_W and grad_b for each layer\n",
    "            \n",
    "            # backpropagation -> from last layer (layer_3) to first layer (layer_0)\n",
    "            # j -> current_layer\n",
    "            # k -> previous_layer\n",
    " \n",
    "            # for layer3\n",
    "            all_partial_derivative_cost_a2 = np.zeros((16, 1))\n",
    "            for j in range(0, 10):              \n",
    "                for k in range(0, 16):\n",
    "                    \n",
    "                    partial_derivative_cost_a3 = 2*(a_layer3[j] - label[j])\n",
    "                    partial_derivative_a3_Z = sigmoid_derivative(Z3[j])\n",
    "                    partial_derivative_Z_W = a_layer2[k]\n",
    "                    partial_derivative_Z_b = 1\n",
    "                    partial_derivative_Z_a2 = W_layer3[j][k]\n",
    "                    \n",
    "                    # chain rule -> update W\n",
    "                    partial_derivative_cost_W = partial_derivative_cost_a3 * partial_derivative_a3_Z * partial_derivative_Z_W                  \n",
    "                    grad_W_layer3[j][k] += partial_derivative_cost_W\n",
    "                    \n",
    "                    # calculate partial derivative of cost with respect to a2 (find partial_derivative_cost_a2)\n",
    "                    all_partial_derivative_cost_a2[k, 0] += partial_derivative_cost_a3 * partial_derivative_a3_Z * partial_derivative_Z_a2\n",
    "                    \n",
    "                # chain rule -> update b\n",
    "                partial_derivative_cost_b = partial_derivative_cost_a3 * partial_derivative_a3_Z * partial_derivative_Z_b\n",
    "                grad_b_layer3[j, 0] += partial_derivative_cost_b\n",
    "                \n",
    "                    \n",
    "            # for layer2\n",
    "            all_partial_derivative_cost_a1 = np.zeros((16, 1))\n",
    "            for j in range(0, 16):  \n",
    "                for k in range(0, 16):\n",
    "                    \n",
    "                    partial_derivative_cost_a2 = all_partial_derivative_cost_a2[j]\n",
    "                    partial_derivative_a2_Z = sigmoid_derivative(Z2[j])\n",
    "                    partial_derivative_Z_W = a_layer1[k]\n",
    "                    partial_derivative_Z_b = 1\n",
    "                    partial_derivative_Z_a1 = W_layer2[j][k]\n",
    "                    \n",
    "                    # chain rule -> update W\n",
    "                    partial_derivative_cost_W = partial_derivative_cost_a2 * partial_derivative_a2_Z * partial_derivative_Z_W\n",
    "                    grad_W_layer2[j, k] += partial_derivative_cost_W\n",
    "                    \n",
    "                    # calculate partial derivative of cost with respect to a1 (find partial_derivative_cost_a1)\n",
    "                    all_partial_derivative_cost_a1[k, 0] += partial_derivative_cost_a2 * partial_derivative_a2_Z * partial_derivative_Z_a1\n",
    "                    \n",
    "                # chain rule -> update b\n",
    "                partial_derivative_cost_b = partial_derivative_cost_a2 * partial_derivative_a2_Z * partial_derivative_Z_b\n",
    "                grad_b_layer2[j, 0] += partial_derivative_cost_b\n",
    "                \n",
    " \n",
    "            # for layer1\n",
    "            for j in range(0, 16):\n",
    "                for k in range(0, 784):\n",
    "                    \n",
    "                    partial_derivative_cost_a1 = all_partial_derivative_cost_a1[j]\n",
    "                    partial_derivative_a_Z = sigmoid_derivative(Z1[j])\n",
    "                    partial_derivative_Z_W = a_layer0[k]\n",
    "                    partial_derivative_Z_b = 1\n",
    "                    \n",
    "                    # chain rule -> update W\n",
    "                    partial_derivative_cost_W = partial_derivative_cost_a1 * partial_derivative_a_Z * partial_derivative_Z_W\n",
    "                    grad_W_layer1[j, k] += partial_derivative_cost_W\n",
    "                    \n",
    "                # chain rule -> update b\n",
    "                partial_derivative_cost_b = partial_derivative_cost_a1 * partial_derivative_a_Z * partial_derivative_Z_b\n",
    "                grad_b_layer1[j, 0] += partial_derivative_cost_b    \n",
    "                \n",
    "    \n",
    "\n",
    "        W_layer1 = W_layer1 - (learning_rate * (grad_W_layer1 / batch_size))\n",
    "        W_layer2 = W_layer2 - (learning_rate * (grad_W_layer2 / batch_size))\n",
    "        W_layer3 = W_layer3 - (learning_rate * (grad_W_layer3 / batch_size))\n",
    "        \n",
    "        b_layer1 = b_layer1 - (learning_rate * (grad_b_layer1 / batch_size))\n",
    "        b_layer2 = b_layer2 - (learning_rate * (grad_b_layer2 / batch_size))\n",
    "        b_layer3 = b_layer3 - (learning_rate * (grad_b_layer3 / batch_size))\n",
    "        \n",
    "        \n",
    "        # calculate cost for images in this batch\n",
    "        for i_image in range(0, batch_size):\n",
    "            \n",
    "            image = batch[i_image][0]\n",
    "            label = batch[i_image][1]\n",
    "        \n",
    "            a_layer0 = image\n",
    "            output_label = label\n",
    "            # find values of hidden layer 1\n",
    "            Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "            a_layer1 = sigmoid(Z1)\n",
    "            # find values of hidden layer 2\n",
    "            Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "            a_layer2 = sigmoid(Z2)\n",
    "            # find values of output layer\n",
    "            Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "            a_layer3 = sigmoid(Z3)\n",
    "\n",
    "            # calculate cost -> cost = Σ{(a_layer3 - y)^2}\n",
    "            cost = 0\n",
    "            for i in range(0, 10):\n",
    "                a = a_layer3[i]\n",
    "                y = label[i]\n",
    "                cost += (a - y)**2\n",
    "            all_costs.append(cost) \n",
    "\n",
    "    # find average of costs in this epoch\n",
    "    sum = 0\n",
    "    for i in range(0, train_set_size):\n",
    "        sum += all_costs[i]\n",
    "    avg_cost = sum / train_set_size\n",
    "    avg_costs_per_epoch.append(avg_cost) # y_axis\n",
    "    epochs.append(i_epoch) # x_axis   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa8b84",
   "metadata": {},
   "source": [
    "#### Calculating accuracy: \n",
    "{Accuracy should be between 25% and 50% at this point!}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07510c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.79\n"
     ]
    }
   ],
   "source": [
    "# calculate output values for 100 first images\n",
    "cnt_correct = 0\n",
    "for i in range(0, train_set_size):\n",
    "\n",
    "    a_layer0 = train_set[i][0]\n",
    "    label = train_set[i][1]\n",
    "    \n",
    "    # find values of hidden layer 1\n",
    "    Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "    a_layer1 = sigmoid(Z1)\n",
    "    \n",
    "    # find values of hidden layer 2\n",
    "    Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "    a_layer2 = sigmoid(Z2)\n",
    "        \n",
    "    # find values of output layer\n",
    "    Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "    a_layer3 = sigmoid(Z3)\n",
    "        \n",
    "    max_value_a_layer3 = a_layer3.max()\n",
    "    output = np.zeros((10, 1))\n",
    "    for j in range(0, 10):\n",
    "        if(a_layer3[j] == max_value_a_layer3):\n",
    "            output[j] = 1\n",
    "    \n",
    "    if((output == label).all()):\n",
    "        cnt_correct += 1\n",
    "        \n",
    "# calculate accuracy\n",
    "accuracy = cnt_correct / train_set_size\n",
    "print(\"Accuracy =\", accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9c174",
   "metadata": {},
   "source": [
    "#### Showing the plot of cost over training epoch (model loss plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb09e75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show cost-epoch plot\n",
    "plt.plot(epochs, avg_costs_per_epoch)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('avg cost')\n",
    "plt.title('model loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad061b3",
   "metadata": {},
   "source": [
    "- - - - \n",
    "\n",
    "## 4. Vectorization\n",
    "\n",
    "By using vectorization, we can increase the speed of calculations and reduce the code execution time significantly. So instead of using the first 100 images, we can use the entire train set data to train our neural network.\n",
    "[In the second section](#feed-forward), we vectorized the feedforward and now we implement the vectorized backpropagation.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Vectorized Cost = (\\vec{a}-\\vec{y})^T(\\vec{a}-\\vec{y})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f04590a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize W matrices with normalize random values\n",
    "W_layer1 = np.random.normal(size=(16, 784))\n",
    "W_layer2 = np.random.normal(size=(16, 16))\n",
    "W_layer3 = np.random.normal(size=(10, 16))\n",
    "\n",
    "# initialize b vectors with zero values\n",
    "b_layer1 = np.zeros((16, 1))\n",
    "b_layer2 = np.zeros((16, 1))\n",
    "b_layer3 = np.zeros((10, 1))\n",
    "\n",
    "# set hyperparameters\n",
    "number_of_epochs = 200\n",
    "learning_rate = 1\n",
    "batch_size = 10\n",
    "\n",
    "train_set_size = 100\n",
    "number_of_batches = int(train_set_size / batch_size) \n",
    "\n",
    "# values of x_axis and y_axis in cost-epoch plot\n",
    "epochs = []\n",
    "avg_costs_per_epoch = []\n",
    "\n",
    "for i_epoch in range(0, number_of_epochs):\n",
    "    \n",
    "    all_costs = []\n",
    "    \n",
    "    for i_batch in range(0, number_of_batches):\n",
    "\n",
    "        batch = train_set[batch_size*i_batch : batch_size*(i_batch+1)]\n",
    "        \n",
    "        grad_W_layer1 = np.zeros((16, 784))\n",
    "        grad_W_layer2 = np.zeros((16, 16))\n",
    "        grad_W_layer3 = np.zeros((10, 16))\n",
    "        \n",
    "        grad_b_layer1 = np.zeros((16, 1))\n",
    "        grad_b_layer2 = np.zeros((16, 1))\n",
    "        grad_b_layer3 = np.zeros((10, 1))\n",
    "        \n",
    "        for i_image in range(0, batch_size):\n",
    "            \n",
    "            image = batch[i_image][0]\n",
    "            label = batch[i_image][1]\n",
    "            \n",
    "            # compute the output for current image\n",
    "            \n",
    "            a_layer0 = image\n",
    "            # find values of hidden layer 1\n",
    "            Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "            a_layer1 = sigmoid(Z1)\n",
    "            # find values of hidden layer 2\n",
    "            Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "            a_layer2 = sigmoid(Z2)\n",
    "            # find values of output layer\n",
    "            Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "            a_layer3 = sigmoid(Z3)\n",
    "            \n",
    "            # calculate cost function -> cost = Transpose(a_layer3 - y) @ (a_layer3 - y)\n",
    "            cost = np.transpose(a_layer3 - label) @ (a_layer3 - label)\n",
    "                \n",
    "                \n",
    "            # update grad_W and grad_b for each layer\n",
    "            \n",
    "            # backpropagation -> from last layer (layer_3) to first layer (layer_0)\n",
    "            # j -> current_layer\n",
    "            # k -> previous_layer\n",
    " \n",
    "            # for layer3\n",
    "\n",
    "            # chain rule -> update W\n",
    "            partial_derivative_cost_W = (2 * (a_layer3 - label) * sigmoid_derivative(Z3)) @ np.transpose(a_layer2)\n",
    "            grad_W_layer3 += partial_derivative_cost_W\n",
    "            \n",
    "            # chain rule -> update b\n",
    "            partial_derivative_cost_b = 2 * (a_layer3 - label) * sigmoid_derivative(Z3)\n",
    "            grad_b_layer3 += partial_derivative_cost_b\n",
    "                \n",
    "            # calculate partial derivative of cost with respect to a2 (find partial_derivative_cost_a2)\n",
    "            partial_derivative_cost_a2 = np.transpose(W_layer3) @ (2 * (a_layer3 - label) * sigmoid_derivative(Z3))\n",
    "            \n",
    "                \n",
    "            # for layer2\n",
    "\n",
    "            # chain rule -> update W\n",
    "            partial_derivative_cost_W = (partial_derivative_cost_a2 * sigmoid_derivative(Z2)) @ np.transpose(a_layer1)\n",
    "            grad_W_layer2 += partial_derivative_cost_W\n",
    "            \n",
    "            # chain rule -> update b\n",
    "            partial_derivative_cost_b = partial_derivative_cost_a2 * sigmoid_derivative(Z2)\n",
    "            grad_b_layer2 += partial_derivative_cost_b\n",
    "                \n",
    "            # calculate partial derivative of cost with respect to a1 (find partial_derivative_cost_a1)\n",
    "            partial_derivative_cost_a1 = np.transpose(W_layer2) @ (partial_derivative_cost_a2 * sigmoid_derivative(Z2))    \n",
    "                \n",
    "                \n",
    "            # for layer1\n",
    "\n",
    "            # chain rule -> update W\n",
    "            partial_derivative_cost_W = (partial_derivative_cost_a1 * sigmoid_derivative(Z1)) @ np.transpose(a_layer0)\n",
    "            grad_W_layer1 += partial_derivative_cost_W\n",
    "            \n",
    "            # chain rule -> update b\n",
    "            partial_derivative_cost_b = partial_derivative_cost_a1 * sigmoid_derivative(Z1)\n",
    "            grad_b_layer1 += partial_derivative_cost_b\n",
    "                   \n",
    "                \n",
    "        W_layer1 = W_layer1 - (learning_rate * (grad_W_layer1 / batch_size))\n",
    "        W_layer2 = W_layer2 - (learning_rate * (grad_W_layer2 / batch_size))\n",
    "        W_layer3 = W_layer3 - (learning_rate * (grad_W_layer3 / batch_size))\n",
    "        \n",
    "        b_layer1 = b_layer1 - (learning_rate * (grad_b_layer1 / batch_size))\n",
    "        b_layer2 = b_layer2 - (learning_rate * (grad_b_layer2 / batch_size))\n",
    "        b_layer3 = b_layer3 - (learning_rate * (grad_b_layer3 / batch_size))\n",
    "        \n",
    "        \n",
    "        # calculate cost for images in this batch\n",
    "        for i_image in range(0, batch_size):\n",
    "            image = batch[i_image][0]\n",
    "            label = batch[i_image][1]\n",
    "        \n",
    "            a_layer0 = image\n",
    "            output_label = label\n",
    "            # find values of hidden layer 1\n",
    "            Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "            a_layer1 = sigmoid(Z1)\n",
    "            # find values of hidden layer 2\n",
    "            Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "            a_layer2 = sigmoid(Z2)\n",
    "            # find values of output layer\n",
    "            Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "            a_layer3 = sigmoid(Z3)\n",
    "\n",
    "            # calculate cost -> cost = Transpose(a_layer3 - y) @ (a_layer3 - y)\n",
    "            cost = np.transpose(a_layer3 - label) @ (a_layer3 - label)\n",
    "            all_costs.append(cost[0]) \n",
    "\n",
    "    # find average of costs in this epoch\n",
    "    sum = 0\n",
    "    for i in range(0, train_set_size):\n",
    "        sum += all_costs[i]\n",
    "    avg_cost = sum / train_set_size\n",
    "    avg_costs_per_epoch.append(avg_cost) # y_axis\n",
    "    epochs.append(i_epoch) # x_axis   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9261b4e",
   "metadata": {},
   "source": [
    "#### Calculating accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c022e3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.98\n"
     ]
    }
   ],
   "source": [
    "# calculate output values for 100 first images\n",
    "cnt_correct = 0\n",
    "for i in range(0, train_set_size):\n",
    "\n",
    "    a_layer0 = train_set[i][0]\n",
    "    label = train_set[i][1]\n",
    "    \n",
    "    # find values of hidden layer 1\n",
    "    Z1 = np.dot(W_layer1, a_layer0) + b_layer1\n",
    "    a_layer1 = sigmoid(Z1)\n",
    "    \n",
    "    # find values of hidden layer 2\n",
    "    Z2 = np.dot(W_layer2, a_layer1) + b_layer2\n",
    "    a_layer2 = sigmoid(Z2)\n",
    "        \n",
    "    # find values of output layer\n",
    "    Z3 = np.dot(W_layer3, a_layer2) + b_layer3\n",
    "    a_layer3 = sigmoid(Z3)\n",
    "        \n",
    "    max_value_a_layer3 = a_layer3.max()\n",
    "    output = np.zeros((10, 1))\n",
    "    for j in range(0, 10):\n",
    "        if(a_layer3[j] == max_value_a_layer3):\n",
    "            output[j] = 1\n",
    "    \n",
    "    if((output == label).all()):\n",
    "        cnt_correct += 1\n",
    "        \n",
    "# calculate accuracy\n",
    "accuracy = cnt_correct / train_set_size\n",
    "print(\"Accuracy =\", accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0277abc3",
   "metadata": {},
   "source": [
    "#### Showing the plot of cost over training epoch (model loss plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea75a0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show cost-epoch plot\n",
    "plt.plot(epochs, avg_costs_per_epoch)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('avg cost')\n",
    "plt.title('model loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
